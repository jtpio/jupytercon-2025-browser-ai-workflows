{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Comprehensive Pandas Tutorial\n\nThis notebook covers essential pandas operations for data analysis, manipulation, and visualization.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 1. Introduction to Pandas\n\nPandas is a powerful Python library for data manipulation and analysis. It provides data structures like DataFrames and Series that make working with structured data easy and intuitive.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set random seed for reproducibility\nnp.random.seed(42)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 2. Creating DataFrames\n\nThere are several ways to create DataFrames in pandas:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# From a dictionary\ndata = {\n    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n    'Age': [25, 30, 35, 40],\n    'City': ['New York', 'Paris', 'London', 'Tokyo']\n}\ndf = pd.DataFrame(data)\n\n# From a list of lists\ndata_list = [\n    ['Alice', 25, 'New York'],\n    ['Bob', 30, 'Paris'],\n    ['Charlie', 35, 'London'],\n    ['David', 40, 'Tokyo']\n]\ndf_list = pd.DataFrame(data_list, columns=['Name', 'Age', 'City'])\n\n# From a NumPy array\narray = np.random.rand(4, 3)\ndf_array = pd.DataFrame(array, columns=['A', 'B', 'C'])\n\n# Display the DataFrames\ndf, df_list, df_array",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 3. Basic DataFrame Operations\n\nLet's explore some fundamental operations with DataFrames.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Create a sample DataFrame for demonstration\ndata = {\n    'Product': ['Laptop', 'Phone', 'Tablet', 'Monitor', 'Keyboard'],\n    'Price': [999, 699, 349, 249, 49],\n    'Quantity': [10, 25, 15, 8, 30],\n    'InStock': [True, True, False, True, True]\n}\ndf_products = pd.DataFrame(data)\n\n# Display basic information\ndf_products.info()\n\n# Show first few rows\ndf_products.head()\n\n# Show basic statistics\ndf_products.describe()\n\n# Access specific columns\ndf_products['Product'], df_products[['Product', 'Price']]\n\n# Filter rows\nexpensive_products = df_products[df_products['Price'] > 300]\nin_stock_products = df_products[df_products['InStock'] == True]\n\nexpensive_products, in_stock_products",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 4. Data Manipulation\n\nPandas provides powerful tools for data manipulation.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Create a sample DataFrame with more data\ndates = pd.date_range('20230101', periods=10)\ndf_sales = pd.DataFrame({\n    'Date': dates,\n    'Product': ['Laptop', 'Phone', 'Tablet', 'Monitor', 'Keyboard', \n                'Laptop', 'Phone', 'Tablet', 'Monitor', 'Keyboard'],\n    'Quantity': [5, 10, 3, 7, 15, 8, 12, 2, 5, 20],\n    'Price': [999, 699, 349, 249, 49, 999, 699, 349, 249, 49],\n    'Region': ['North', 'South', 'East', 'West', 'North', \n               'South', 'East', 'West', 'North', 'South']\n})\n\n# Add a new column\ndf_sales['Revenue'] = df_sales['Quantity'] * df_sales['Price']\n\n# Sort by date\ndf_sorted = df_sales.sort_values('Date')\n\n# Group by product and calculate total revenue\ngrouped = df_sales.groupby('Product').agg({\n    'Quantity': 'sum',\n    'Revenue': 'sum',\n    'Price': 'mean'\n}).reset_index()\n\n# Pivot table\npivot = pd.pivot_table(df_sales, \n                       values='Revenue', \n                       index='Product', \n                       columns='Region', \n                       aggfunc='sum', \n                       fill_value=0)\n\ndf_sorted.head(), grouped, pivot",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 5. Data Visualization with Pandas\n\nPandas integrates with Matplotlib for easy visualization.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Set up the plot style\nplt.style.use('seaborn')\n\n# Create a figure with multiple plots\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# Plot 1: Line plot of sales over time\ndf_sales.set_index('Date')['Revenue'].plot(ax=axes[0, 0], title='Revenue Over Time')\n\n# Plot 2: Bar plot of total revenue by product\ngrouped.set_index('Product')['Revenue'].sort_values().plot(kind='bar', ax=axes[0, 1], title='Revenue by Product')\n\n# Plot 3: Pie chart of quantity by region\ndf_sales.groupby('Region')['Quantity'].sum().plot(kind='pie', autopct='%1.1f%%', ax=axes[1, 0], title='Quantity by Region')\n\n# Plot 4: Scatter plot of price vs quantity\ncolors = {'North':'red', 'South':'blue', 'East':'green', 'West':'purple'}\naxes[1, 1].scatter(\n    x=df_sales['Price'],\n    y=df_sales['Quantity'],\n    c=df_sales['Region'].map(colors),\n    alpha=0.7\n)\naxes[1, 1].set_title('Price vs Quantity by Region')\naxes[1, 1].set_xlabel('Price')\naxes[1, 1].set_ylabel('Quantity')\n\nplt.tight_layout()\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 6. Best Practices and Tips\n\n1. **Use meaningful column names**: Makes your code more readable and self-documenting.\n2. **Handle missing data**: Use `dropna()` or `fillna()` appropriately.\n3. **Avoid chained indexing**: Use `.loc[]` for assignment to prevent SettingWithCopyWarning.\n4. **Leverage vectorized operations**: They're faster than looping through rows.\n5. **Use categorical data types**: For columns with limited unique values to save memory.\n6. **Optimize data types**: Use appropriate dtypes (e.g., int32 instead of int64 when possible).\n7. **Use query() for complex filtering**: Can be more readable than boolean indexing.\n8. **Consider memory usage**: Especially important with large datasets.\n\n## 7. Handling Missing Data\n\nPandas provides several methods to handle missing data:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Create a DataFrame with missing values\ndf_missing = df_sales.copy()\ndf_missing.loc[[1, 3, 5], 'Quantity'] = np.nan\ndf_missing.loc[[2, 4, 6], 'Price'] = np.nan\n\n# Check for missing values\ndf_missing.isna().sum()\n\n# Different ways to handle missing values\n\n# 1. Drop rows with missing values\ndf_dropped = df_missing.dropna()\n\n# 2. Fill with a specific value\ndf_filled_zero = df_missing.fillna(0)\ndf_filled_mean = df_missing.fillna({\n    'Quantity': df_missing['Quantity'].mean(),\n    'Price': df_missing['Price'].mean()\n})\n\n# 3. Forward fill\n df_filled_ffill = df_missing.fillna(method='ffill')\n\n# 4. Interpolate\ndf_interpolated = df_missing.interpolate()\n\ndf_missing.head(), df_dropped.head(), df_filled_mean.head(), df_interpolated.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 8. Conclusion\n\nThis notebook covered the essential pandas operations for data analysis:\n- Creating and exploring DataFrames\n- Basic operations and filtering\n- Data manipulation and transformation\n- Grouping and aggregation\n- Data visualization\n- Handling missing data\n\nPandas is a powerful tool that can handle complex data operations with just a few lines of code. The key to mastering pandas is practice - try these examples with your own datasets!",
      "metadata": {}
    }
  ]
}